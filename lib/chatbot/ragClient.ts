// ========================================
// CLIENT RAG - Interrogation Vector Store OpenAI
// ========================================
// N√©cessite OPENAI_API_KEY dans les variables d'environnement
// Le vector store utilis√© est vs_68e87a07ae6c81918d805c8251526bda

import OpenAI from "openai";

// ID du vector store endobiog√©nie h√©berg√© chez OpenAI
const VECTOR_STORE_ID = "vs_68e87a07ae6c81918d805c8251526bda";

/**
 * Chunk de texte retourn√© par le vector store
 */
export interface RAGChunk {
  text: string;
  score?: number;
}

/**
 * Client OpenAI singleton
 */
let openaiClient: OpenAI | null = null;

/**
 * R√©cup√®re ou cr√©e le client OpenAI
 */
function getOpenAIClient(): OpenAI {
  if (!openaiClient) {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      throw new Error(
        "OPENAI_API_KEY non configur√©e dans les variables d'environnement"
      );
    }
    openaiClient = new OpenAI({ apiKey });
  }
  return openaiClient;
}

/**
 * Assistant ID (cr√©√© √† la vol√©e ou r√©utilis√©)
 * Pour √©viter de cr√©er un assistant √† chaque requ√™te, on pourrait
 * le cr√©er une fois et stocker son ID. Pour l'instant, on le cr√©e √† la vol√©e.
 */
let cachedAssistantId: string | null = null;

/**
 * V√©rifie que le vector store existe et est accessible
 */
async function checkVectorStore(client: OpenAI): Promise<boolean> {
  try {
    console.log("üîç V√©rification du vector store:", VECTOR_STORE_ID);
    const vectorStore = await client.beta.vectorStores.retrieve(VECTOR_STORE_ID);
    console.log("‚úÖ Vector store trouv√©:", vectorStore.name, "| Status:", vectorStore.status);
    console.log("‚úÖ Fichiers dans le vector store:", vectorStore.file_counts.completed);

    if (vectorStore.status !== "completed") {
      console.warn("‚ö†Ô∏è Vector store pas encore compl√©t√©:", vectorStore.status);
      return false;
    }

    return true;
  } catch (error: any) {
    console.error("‚ùå Vector store inaccessible:", error.message);
    return false;
  }
}

/**
 * Cr√©e ou r√©cup√®re un assistant configur√© avec file_search
 */
async function getOrCreateAssistant(client: OpenAI): Promise<string> {
  if (cachedAssistantId) {
    return cachedAssistantId;
  }

  try {
    // V√©rifier le vector store avant de cr√©er l'assistant
    const vsOk = await checkVectorStore(client);
    if (!vsOk) {
      throw new Error("Vector store indisponible ou non compl√©t√©");
    }

    // Cr√©er un assistant avec file_search et notre vector store
const assistant = await client.beta.assistants.create({
  name: "Endobiogenie RAG Assistant",
  instructions:
    "Tu es un assistant sp√©cialis√© en endobiog√©nie. " +
    "\n\nR√àGLES STRICTES :\n" +
    "1. R√©ponds UNIQUEMENT √† partir des informations retrouv√©es dans les documents du vector store.\n" +
    "2. Si une information n'est pas disponible, dis simplement : \"Je n'ai pas d'information sp√©cifique √† ce sujet.\"\n" +
    "3. NE MENTIONNE JAMAIS les sources, livres, volumes, pages, sections ou chapitres.\n" +
    "4. NE DIS JAMAIS des phrases comme \"Ce point est d√©taill√© dans les volumes\" ou \"Pas de d√©tail dans les volumes\".\n" +
    "5. R√©ponds de mani√®re naturelle et fluide, comme si tu expliquais directement √† partir de tes connaissances.\n" +
    "\n" +
    "Fournis des passages clairs et pr√©cis sur la logique fonctionnelle du terrain, " +
    "les axes neuroendocriniens et l'interpr√©tation des index BdF. " +
    "Sois p√©dagogique et accessible. Ta r√©ponse doit √™tre autonome et compl√®te, sans aucune r√©f√©rence bibliographique.",
  model: process.env.OPENAI_MODEL || "gpt-4o-mini",
      tools: [{ type: "file_search" }],
      tool_resources: {
        file_search: {
          vector_store_ids: [VECTOR_STORE_ID],
        },
      },
    });

    cachedAssistantId = assistant.id;
    return assistant.id;
  } catch (error: any) {
    console.error("‚ùå Erreur cr√©ation assistant:", error);
    throw new Error(`Impossible de cr√©er l'assistant: ${error.message}`);
  }
}

/**
 * Interroge le vector store OpenAI avec une query
 * @param userQuery - Requ√™te textuelle de l'utilisateur
 * @param topK - Nombre de chunks √† retourner (par d√©faut 3)
 * @returns Tableau de chunks pertinents
 */
export async function queryVectorStore(
  userQuery: string,
  topK: number = 3
): Promise<RAGChunk[]> {
  try {
    const client = getOpenAIClient();

    // 1. R√©cup√©rer ou cr√©er l'assistant
    console.log("üîç Cr√©ation/r√©cup√©ration de l'assistant...");
    const assistantId = await getOrCreateAssistant(client);
    console.log("‚úÖ Assistant ID:", assistantId);

    // 2. Cr√©er un thread
    console.log("üîç Cr√©ation du thread...");
    const thread = await client.beta.threads.create();
    console.log("‚úÖ Thread ID:", thread.id);

    // 3. Ajouter le message utilisateur
    console.log("üîç Ajout du message utilisateur...");
    await client.beta.threads.messages.create(thread.id, {
      role: "user",
      content: userQuery,
    });

    // 4. Lancer le run avec file_search (avec timeout de 90 secondes)
    console.log("üîç Lancement du run avec file_search...");
    const startTime = Date.now();
    const run = await Promise.race([
      client.beta.threads.runs.createAndPoll(thread.id, {
        assistant_id: assistantId,
        // Augmenter le poll_interval pour r√©duire la fr√©quence de v√©rification
        poll_interval_ms: 2000, // V√©rifier toutes les 2 secondes au lieu de 1
      }),
      new Promise((_, reject) =>
        setTimeout(() => reject(new Error("Timeout: le vector store met trop de temps √† r√©pondre (>90s)")), 90000)
      )
    ]) as OpenAI.Beta.Threads.Runs.Run;

    const duration = Date.now() - startTime;
    console.log(`‚úÖ Run compl√©t√© en ${duration}ms`);

    console.log("‚úÖ Run status:", run.status);

    // 5. V√©rifier le statut du run
    if (run.status !== "completed") {
      console.error("‚ùå Run non compl√©t√©:", run.status);

      if (run.last_error) {
        console.error("‚ùå Erreur d√©taill√©e:", run.last_error);
        console.error("‚ùå Code erreur:", run.last_error.code);
        console.error("‚ùå Message erreur:", run.last_error.message);
      }

      // Log des √©tapes du run pour debug
      if (run.required_action) {
        console.log("üîç Action requise:", run.required_action);
      }

      console.log("‚ö†Ô∏è Utilisation des chunks par d√©faut suite √† run non compl√©t√©");
      return getDefaultChunks();
    }

    // 6. R√©cup√©rer les messages de l'assistant
    console.log("üîç R√©cup√©ration des messages...");
    const messages = await client.beta.threads.messages.list(thread.id);
    console.log("‚úÖ Nombre de messages:", messages.data.length);

    // 7. Extraire les r√©ponses textuelles
    const chunks: RAGChunk[] = [];

    for (const message of messages.data) {
      if (message.role === "assistant") {
        for (const content of message.content) {
          if (content.type === "text") {
            const text = content.text.value;
            console.log("‚úÖ Texte re√ßu de l'assistant (longueur):", text.length);

            // Nettoyer les annotations/citations si pr√©sentes
            let cleanedText = text;

            // Enlever les r√©f√©rences de type„ÄêX‚Ä†source„Äë
            cleanedText = cleanedText.replace(/„Äê\d+‚Ä†[^„Äë]+„Äë/g, "");

            // D√©couper en paragraphes significatifs
            const paragraphs = cleanedText
              .split("\n\n")
              .map((p) => p.trim())
              .filter((p) => p.length > 50); // Min 50 caract√®res

            console.log("‚úÖ Paragraphes extraits:", paragraphs.length);

            // Prendre les premiers paragraphes jusqu'√† topK
            for (let i = 0; i < Math.min(paragraphs.length, topK); i++) {
              chunks.push({
                text: paragraphs[i],
                score: 1.0 - i * 0.1, // Score d√©croissant arbitraire
              });
            }

            break; // On ne garde que le premier message assistant
          }
        }
        break;
      }
    }

    console.log("‚úÖ Nombre total de chunks:", chunks.length);

    // 8. Nettoyer le thread (optionnel, √©conomise les tokens)
    try {
      await client.beta.threads.del(thread.id);
      console.log("‚úÖ Thread supprim√©");
    } catch (e) {
      console.warn("‚ö†Ô∏è Impossible de supprimer le thread:", e);
    }

    return chunks.slice(0, topK);
  } catch (error: any) {
    console.error("‚ùå Erreur lors de la requ√™te vector store:", error);
    console.error("‚ùå Message d'erreur:", error.message);
    console.error("‚ùå Stack:", error.stack);

    // En cas d'erreur, retourner des chunks par d√©faut
    console.log("‚ö†Ô∏è Utilisation des chunks par d√©faut");
    return getDefaultChunks();
  }
}

/**
 * Chunks par d√©faut en cas d'erreur d'acc√®s au vector store
 */
function getDefaultChunks(): RAGChunk[] {
  return [
    {
      text:
        "L'axe corticotrope (ACTH ‚Üí cortisol) coordonne la r√©ponse d'urgence et oriente le catabolisme rapide. " +
        "Il mobilise les substrats √©nerg√©tiques et module l'inflammation en situation de stress.",
      score: 1.0,
    },
    {
      text:
        "L'axe thyr√©otrope r√©gule la vitesse m√©tabolique tissulaire et la capacit√© de r√©ponse cellulaire. " +
        "Un index thyro√Ødien efficace refl√®te un bon rendement fonctionnel des hormones thyro√Ødiennes en p√©riph√©rie.",
      score: 0.9,
    },
    {
      text:
        "Le syst√®me gonadotrope module l'anabolisme de fond via les androg√®nes et les ≈ìstrog√®nes, " +
        "impactant le renouvellement tissulaire et la pression pro-croissance.",
      score: 0.8,
    },
  ];
}
